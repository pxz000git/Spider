　　文/IT爆料汇　　这个冬天，总有人想要把黑手伸向孩子。　　你说我家孩子没上三色幼儿园，在家看动画片呢。但你可能没发现，PAD里花花绿绿看似正常的动画片画面，实则上演着一幕幕血腥暴力或者“屎尿屁”的肮脏污秽，毒害着孩子。　　关于儿童“邪典”（cult）视频最近引发了不少讨论。这种成人世界里一看就感到严重不适的东西，孩子们却看得下去，并且可以用“喜欢”这个词来形容。这虽然让人难以置信，但却是真的。　　从数据上可以窥见得一斑：据此事最初的揭发者微博大V肉呆大魔王在舆论发酵前的统计称，在某国内主流视频网站的母婴视频频道，大概有几百个这样充满性暗示和暴力暗示的视频，频道总计有150万粉丝，单个视频观看量高达660万。　　　　弗洛伊德曾将人的性心理发展划分为5个阶段：①口欲期；②肛欲期；③性蕾欲期；④潜伏期；⑤生殖期。　　其中1~3岁是肛门期，3-6岁是性蕾欲期，这两个时期孩子对于那些儿童“邪典”视频中涉及到的屎尿屁，血腥暴力很感兴趣。　　但肛欲期和性蕾欲期只是幼儿进行自我探索的一个必经阶段。在这期间，只需要家长有正常的引导，或者孩子正常的感知这个世界，就基本没什么问题了。　　但弗洛伊德同时也提出：成人人格的基本组成部分在前三个发展阶段已基本形成，所以儿童的早年环境、早期经历对其成年后的人格形成起着重要的作用，许多成人的变态心理、心理冲突都可追溯到早年期创伤性经历和压抑的情结。　　对家长们来说，在早期儿童心理发展的这些阶段，虽然会自然地过度过去，但是仍需小心的看护，一旦出现问题，将是终身不可逆的影响。　　而这些邪典视频的传播者和制作者，看到的只是点击率和广告分成，哪里还会管后续会造成什么什么影响。　　其实抛开弗洛伊德的理论，依然可以用最直观的方式感知到这种视频的危害。　　在这些邪典视频里，冰雪奇缘的艾莎公主和蜘蛛侠是最常出现的两个卡通人物，他们经常会演绎各种低俗的画面，比如：亲亲、抱抱、蜘蛛侠偷看艾莎洗澡。　　而孩子的认知还处在初级阶段，当两个事物总是同时出现时，孩子们的大脑就会产生经典反射。一个事物出现，脑中另一个事物也会跟着出现，认为这是正常的。　　那如果喜欢当艾莎公主孩子，遇到扮演蜘蛛侠的猥琐大叔，是不是认为被亲亲抱抱是理所应当的？　　　　在此事没有引起视频网站注意的时候，如果你去相关网站搜关键词，会自动跳出来一堆联想词。　　并且“儿童邪典片”在优酷、爱奇艺、腾讯视频网站中都正大光明地出现在“少儿”、“亲子”等门类之下。　　一旦小朋友观看了几部视频之后，平台就会推荐更多同类视频，形成恶性循环。而这恰恰是视频网站中一直引以为傲的“千人千面”人工智能推荐。　　但这一次的儿童“邪典”视频事件又一次狠狠打了算法的脸。现在是个互联网公司都说自己在研究人工智能，视频网站当然也不例外。　　在去年9月5日，阿里巴巴大优酷事业群总裁杨伟东那边在第九届中国网络视听产业论坛上表示，正在推进优酷视频产品个性化推荐机制，即所谓的“千人千面”据介绍，这一灵感来自于手机淘宝，而试行“千人千面”后，优酷移动端的首页点击率、观看时长和活跃度都有较为明显的提升。“每年都有大量新内容上线，但其中很大一部分可能因为平台排播和宣推资源分配，没有机会充分触达目标用户，千人千面就解决了这个问题。”　　爱奇艺在去年6月份的“爱奇艺世界·大会”上也着重强调自己开始玩AI了。　　并且除了千人千面的精准推荐，还有更高级的：会把视频分解成不同的镜头，每个镜头分解成不同的画面，然后给每个不同的画面打上各种标签，一个镜头可能有上百个画面，通过大量的标签，配合文本识别，以此更加进行精准的广告投放。　　可是你看，正是这种精准的、智能的推荐，让儿童“邪典”片，推荐的更精准，也波及的更广泛。　　除了推荐上精准，这些视频为什么能够轻易经过审核？这恐怕还是得说视频网站实在太过相信自己的技术。　　对于视频的审核，业界通用的一般会分为如下几个步骤：　　①机器审核　　②图像方面：对一些视频抽帧来做审核。　　③上传者方面：通过同一ID的上传记录，对用户进行用户画像，对于某些高危用户做重点审核。　　④文字方面：关键字排查 　　⑤设立复审、QA环节保障审核准确率以及难以确认的视频审核。　　⑥视频底部评论方面　　在YouTube上还会增加内容分级机制。国内目前没有这个机制，但是这个机制基本上也杜绝不了评级为“儿童”的内容，依旧乌烟瘴气。　　这几个步骤中，第一条机器审核号称能够判断出99%的内容，剩下只有1%需要再次动用人工。人工的图像审核即是对于机器没有通过的视频，审核的工作人员会把其每6秒截图，一页60张图，以此来节省时间。　　但很多“邪典”视频在第一步机器审核中就能轻而易举的通过，原因是机器审核视频原理是先建模，然后导入海量的违禁视频，让多个机器同时进行深度样本学习，再标注无法通过的图像种类，进而把这些样本揉碎、旋转、添加“噪音”，提高机器识别能力。　　这其中拼的不止是技术，还有样本图库的大小。图普科技的样本库中，有超过1亿的色情样本和千万级别的极端宗教主义样本特征。　　但是儿童“邪典”视频压根就不在样本库中，又如何能审核出来，在机器看来，它跟正常的动画片也没有太大区别。　　机器审核过了，人工自然不会花力气多看。文字标题方面也没有明显的黄暴，仅是：米老鼠打针，爱莎公主治病．．．．．．这样平和的表述而已。　　所以算法和智能，目前来看依旧在别有用心的欺骗者面前完败。　　内容这种具有强烈主观意味的产物，仍然是人工智能的天敌。　　现在仅仅一个语义理解还是在非常初级的简单句阶段，如果过渡到更复杂维度更广的视频审核，瞒过机器更是轻而易举。　　　　算法这个东西，好是好，就是没“人性”。这一点在视频网站上表现的不明显，在成也算法，败也算法的“今日头条”上却尤其突出。　　比如我只是偶尔点两次“李小璐”，结果就一直不断地给我推“李小璐”“贾乃亮”和各种娱乐明星八卦文章。　　这就形成了越来越窄的信息圈子，并且效应也不断的增加。　　而普通大众偏偏就是对娱乐、生活感兴趣，又加上各种标题党的推波助澜，所以慢慢的，头条重度用户可能对所有的明星八卦如数家珍，可是却不知今年物价房价涨势如何，有没有什么新技术将要落地。　　曾扬言算法就是其一切的头条如今也乖乖的在招2000个编辑。但当年头条的状态，是每过一段时间，都会发布《反色情低俗处罚通告》，封禁或禁言一批不规矩的头条号，反反复复，最后终于面临大劫。　　人工智能在经过了去年一年的吹嘘之后，泡沫不少。　　就目前来看，它在很多领域难言替代，而这次的儿童邪典视频事件，技术成了灾难的传播者。　　对待人工智能和机器算法，尚应慎待之，慎用之。
										
									